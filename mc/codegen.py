from mc.graph import Graph
from mc.node import Node, IndexNode
from typing import Dict
import mc.operators as ops
import numpy as np
from mc.utils import cpp_type, CodeWriter
import os

class CodeGen(CodeWriter):
    name_dict: Dict[str, str]
    codegen_dir: str
    data_dir: str
    def __init__(self, graph: Graph, codegen_dir, data_dir):
        super().__init__()
        self.graph = graph
        self.name_dict = {}
        self.codegen_dir = codegen_dir
        self.data_dir = data_dir

    def node_name(self, node: Node):
        if node.name not in self.name_dict:
            node_name = node.name
            node_name = node_name.replace('/', '_')
            node_name = node_name.replace('::', '_')
            node_name = node_name.replace('.', '_')
            if not node_name.replace('_', '').isalnum() or '__' in node_name:
                raise ValueError(f'Node name {node_name} is not valid')
            self.name_dict[node.name] = node_name
        return self.name_dict[node.name]

    def tensor_name(self, inode: IndexNode):
        return f'{self.node_name(inode.node)}__{inode.index}'

    def write_helper_code(self):
        code_template = r'''// generated by MCCompiler
#include <cstdio>
#include <cstdlib>
#include <string>
#include <fstream>
#include <cuda.h>
#include <cublas_v2.h>

#define UNREACHABLE() { \
    printf("file %s line %i: unreachable!\n", __FILE__, __LINE__); \
    fflush(stdout); \
    exit(1); \
}

static const char *cublasGetErrorString(cublasStatus_t error) {
    switch (error)
    {
        case CUBLAS_STATUS_SUCCESS:
            return "CUBLAS_STATUS_SUCCESS";
        case CUBLAS_STATUS_NOT_INITIALIZED:
            return "CUBLAS_STATUS_NOT_INITIALIZED";
        case CUBLAS_STATUS_ALLOC_FAILED:
            return "CUBLAS_STATUS_ALLOC_FAILED";
        case CUBLAS_STATUS_INVALID_VALUE:
            return "CUBLAS_STATUS_INVALID_VALUE";
        case CUBLAS_STATUS_ARCH_MISMATCH:
            return "CUBLAS_STATUS_ARCH_MISMATCH";
        case CUBLAS_STATUS_MAPPING_ERROR:
            return "CUBLAS_STATUS_MAPPING_ERROR";
        case CUBLAS_STATUS_EXECUTION_FAILED:
            return "CUBLAS_STATUS_EXECUTION_FAILED";
        case CUBLAS_STATUS_INTERNAL_ERROR:
            return "CUBLAS_STATUS_INTERNAL_ERROR";
        default:
            return "<unknown>";
    }
    UNREACHABLE()
}

#define checkCudaErrors(stmt) {                                 \
    cudaError_t err = stmt;                            \
    if (err != cudaSuccess) {                          \
    fprintf(stderr, "%s in file %s, function %s, line %i: %04d %s\n", #stmt, __FILE__, __FUNCTION__, __LINE__, err, cudaGetErrorString(err)); \
    exit(1); \
    }                                                  \
}

#define checkBlasErrors(stmt) { \
    cublasStatus_t err = stmt; \
    if (err != CUBLAS_STATUS_SUCCESS) {                          \
    fprintf(stderr, "%s in file %s, function %s, line %i: %04d %s\n", #stmt, __FILE__, __FUNCTION__, __LINE__, err, cublasGetErrorString(err)); \
    exit(1); \
    } \
}

void load_tensor(std::string f_name, void* buffer, size_t size, bool on_gpu=true) {
    std::ifstream f(f_name.c_str(), std::ios::in | std::ios::binary);
    if (!f.is_open()) {
        fprintf(stderr, "Cannot open file %s", f_name.c_str());
        exit(1);
    }
    if (on_gpu) {
        void* tmp_buffer = malloc(size);
        f.read((char*)tmp_buffer, size);
        checkCudaErrors(cudaMemcpy(buffer, tmp_buffer, size, cudaMemcpyHostToDevice));
        free(tmp_buffer);
    } else {
        f.read((char*) buffer, size);
    }
    f.close();
}
    '''
        self.write(code_template)

    def write_init_code(self):
        node_list = self.graph.topological_sort()
        self.wl('char* cuda_buffer;')
        for node in node_list:
            if not isinstance(node, ops.Input):
                for i in range(len(node.output_types)):
                    self.wl(f'{cpp_type(node.output_types[i].dtype)}* {self.tensor_name(IndexNode(node, i))};')
        self.wl('')
        buffer_size = 0
        for node in node_list:
            if not isinstance(node, ops.Input):
                for i in range(len(node.output_types)):
                    buffer_size += node.output_types[i].size() * node.output_types[i].dtype.itemsize
        buffer_ptr = 0
        self.wl('void init()')
        self.block_start()
        self.wl(f'checkCudaErrors(cudaMalloc(&cuda_buffer, {buffer_size}));')
        for node in node_list:
            if not isinstance(node, ops.Input):
                for i in range(len(node.output_types)):
                    self.wl(f'{self.tensor_name(IndexNode(node, i))} = ({cpp_type(node.output_types[i].dtype)}*)(cuda_buffer + {buffer_ptr}); /* {node.output_types[i].shape} * {node.output_types[i].dtype.itemsize} */')
                    buffer_ptr += node.output_types[i].size() * node.output_types[i].dtype.itemsize
        for node in node_list:
            if isinstance(node, ops.Constant):
                self.wl(f'load_tensor("{self.tensor_name(IndexNode(node, 0))}.bin", {self.tensor_name(IndexNode(node, 0))}, {node.output_types[0].size() * node.output_types[0].dtype.itemsize});')
        assert buffer_ptr == buffer_size
        self.block_end()
        self.wl('')


    def write_kernels(self):
        node_list = self.graph.topological_sort()
        for node in node_list:
            if isinstance(node, (ops.Input, ops.Constant, ops.Output)):
                continue
            params = [f'{cpp_type(t.dtype)}* input{i}' for i, t in enumerate(node.input_types)]
            params += [f'{cpp_type(t.dtype)}* output{i}' for i, t in enumerate(node.output_types)]
            func_sig =  f"void kernel_{self.node_name(node)}({', '.join(params)})"
            self.wl(f'// {node}')
            self.wl(f'// {node.input_types}')
            self.wl(f'// {node.output_types}')
            self.write(node.get_cuda_code(func_sig))
            self.wl('')
        
        run_params = []
        for node in self.graph.inputs:
            assert isinstance(node, ops.Input)
            run_params.append(f'{cpp_type(node.output_types[0].dtype)}* {self.tensor_name(IndexNode(node, 0))}')
        for i, node in enumerate(self.graph.outputs):
            assert isinstance(node, ops.Output)
            run_params.append(f'{cpp_type(node.input_types[0].dtype)}* &output{i}')
        
        self.wl(f'void run({", ".join(run_params)})')
        self.block_start()
        for node in node_list:
            if isinstance(node, (ops.Input, ops.Constant, ops.Output)):
                continue
            params = [self.tensor_name(input_node) for input_node in node.input_nodes]
            params += [self.tensor_name(IndexNode(node, i)) for i in range(len(node.output_types))]
            self.wl(f'kernel_{self.node_name(node)}({", ".join(params)});')
        
        for i, node in enumerate(self.graph.outputs):
            assert isinstance(node, ops.Output)
            assert len(node.input_nodes) == 1
            self.wl(f'output{i} = {self.tensor_name(node.input_nodes[0])};')
        self.block_end()
        self.wl('')


    def write_test_code(self):
        self.wl('int main()')
        self.block_start()
        self.wl('init();')
        for i, node in enumerate(self.graph.inputs):
            assert isinstance(node, ops.Input)
            size = node.output_types[0].size() * node.output_types[0].dtype.itemsize
            self.wl(f'{cpp_type(node.output_types[0].dtype)}* {self.tensor_name(IndexNode(node, 0))}; // input{i}')
            self.wl(f'checkCudaErrors(cudaMalloc(&{self.tensor_name(IndexNode(node, 0))}, {size}));')
            self.wl(f'load_tensor("{os.path.join(self.data_dir, f"input{i}")}.bin", {self.tensor_name(IndexNode(node, 0))}, {size});')
        for i, node in enumerate(self.graph.outputs):
            assert isinstance(node, ops.Output)
            size = node.input_types[0].size() * node.input_types[0].dtype.itemsize
            self.wl(f'{cpp_type(node.input_types[0].dtype)}* {self.tensor_name(node.input_nodes[0])}; // output{i}')
            self.wl(f'{cpp_type(node.input_types[0].dtype)}* {self.tensor_name(node.input_nodes[0])}_ref;')
            self.wl(f'{cpp_type(node.input_types[0].dtype)}* {self.tensor_name(node.input_nodes[0])}_cpu;')
            self.wl(f'{self.tensor_name(node.input_nodes[0])}_ref = ({cpp_type(node.input_types[0].dtype)}*) malloc({size});')
            self.wl(f'{self.tensor_name(node.input_nodes[0])}_cpu = ({cpp_type(node.input_types[0].dtype)}*) malloc({size});')
            self.wl(f'load_tensor("{os.path.join(self.data_dir, f"output{i}")}.bin", {self.tensor_name(node.input_nodes[0])}_ref, {size}, false);')
        self.wl('run(' + ', '.join([self.tensor_name(IndexNode(node, 0)) for node in self.graph.inputs] + [self.tensor_name(node.input_nodes[0]) for node in self.graph.outputs]) + ');')
        self.wl('return 0;')
        self.block_end()

    def write_code(self):
        self.write_helper_code()
        self.write_init_code()
        self.write_kernels()
        self.write_test_code()


def codegen(graph, codegen_dir, data_dir):
    writer = CodeGen(graph, codegen_dir, data_dir)
    writer.write_code()
    print(writer.code_str)
    os.makedirs(codegen_dir, exist_ok=True)
    with open(os.path.join(codegen_dir, 'gen.cu'), 'w') as f:
        f.write(writer.code_str)
    os.system(f"nvcc -std=c++11 -arch=sm_70 -O3 -o {os.path.join(codegen_dir, 'gen')} {os.path.join(codegen_dir, 'gen.cu')}")

    # TODO: save constants
